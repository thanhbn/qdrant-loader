"""Code chunk processor for creating enhanced code chunk documents."""

from typing import Any, Dict, Tuple

import structlog

from qdrant_loader.core.chunking.strategy.base.chunk_processor import BaseChunkProcessor
from qdrant_loader.core.document import Document

logger = structlog.get_logger(__name__)


class CodeChunkProcessor(BaseChunkProcessor):
    """Chunk processor for code documents with programming language context."""
    
    def __init__(self, settings):
        """Initialize the code chunk processor.
        
        Args:
            settings: Configuration settings
        """
        super().__init__(settings)
        self.logger = logger
        
        # Code-specific configuration
        self.code_config = getattr(settings.global_config.chunking.strategies, 'code', None)
        self.max_chunk_size_for_nlp = getattr(self.code_config, 'max_chunk_size_for_nlp', 20000)
        
        # NLP skip conditions for code
        self.skip_conditions = {
            "large_content": self.max_chunk_size_for_nlp,
            "binary_patterns": ['\x00', '\xFF', '\xFE'],
            "minified_code_threshold": 0.1,  # Ratio of meaningful chars
            "generated_code_patterns": ['auto-generated', 'do not edit', 'generated by']
        }
    
    def create_chunk_document(self, original_doc: Document, chunk_content: str,
                            chunk_index: int, total_chunks: int,
                            chunk_metadata: Dict[str, Any], skip_nlp: bool = False) -> Document:
        """Create a document for a code chunk with enhanced metadata.
        
        Args:
            original_doc: The original document being chunked
            chunk_content: The content of this chunk
            chunk_index: Index of this chunk (0-based)
            total_chunks: Total number of chunks
            chunk_metadata: Metadata specific to this chunk
            skip_nlp: Whether to skip semantic analysis for this chunk
            
        Returns:
            Document instance representing the code chunk
        """
        # Generate unique chunk ID
        chunk_id = self.generate_chunk_id(original_doc, chunk_index)
        
        # Create base metadata
        base_metadata = self.create_base_chunk_metadata(
            original_doc, chunk_index, total_chunks, chunk_metadata
        )
        
        # Add code-specific metadata
        code_metadata = self._create_code_specific_metadata(chunk_content, chunk_metadata, original_doc)
        base_metadata.update(code_metadata)
        
        # Determine if we should skip NLP for this chunk
        if not skip_nlp:
            skip_nlp, skip_reason = self.should_skip_semantic_analysis(chunk_content, chunk_metadata)
            if skip_nlp:
                base_metadata["nlp_skip_reason"] = skip_reason
        
        # Create chunk document
        chunk_doc = Document(
            id=chunk_id,
            content=chunk_content,
            metadata=base_metadata,
            source=original_doc.source,
            source_type=original_doc.source_type,
            url=original_doc.url,
            content_type=original_doc.content_type,
            title=self._generate_chunk_title(original_doc, chunk_metadata, chunk_index)
        )
        
        return chunk_doc
    
    def should_skip_semantic_analysis(self, chunk_content: str, 
                                    chunk_metadata: Dict[str, Any]) -> Tuple[bool, str]:
        """Determine whether to skip semantic analysis for a code chunk.
        
        Args:
            chunk_content: Content of the chunk
            chunk_metadata: Metadata for the chunk
            
        Returns:
            Tuple of (should_skip, reason)
        """
        content_length = len(chunk_content)
        
        # Skip if content is too large
        if content_length > self.skip_conditions["large_content"]:
            return True, "content_too_large"
        
        # Skip if content appears to be binary
        if any(pattern in chunk_content for pattern in self.skip_conditions["binary_patterns"]):
            return True, "binary_content"
        
        # Skip if content appears to be minified
        if self._is_minified_code(chunk_content):
            return True, "minified_code"
        
        # Skip if content appears to be auto-generated
        if self._is_generated_code(chunk_content):
            return True, "generated_code"
        
        # Skip if it's mostly comments (low semantic value)
        if self._is_mostly_comments(chunk_content):
            return True, "mostly_comments"
        
        # Skip test files with many assertions (low semantic complexity)
        if chunk_metadata.get('element_type') == 'test' and content_length < 500:
            return True, "simple_test_code"
        
        # Skip configuration or data files
        if chunk_metadata.get('language') in ['json', 'yaml', 'xml', 'ini']:
            return True, "configuration_file"
        
        return False, "suitable_for_nlp"
    
    def _create_code_specific_metadata(self, content: str, chunk_metadata: Dict[str, Any], 
                                     original_doc: Document) -> Dict[str, Any]:
        """Create code-specific metadata for the chunk.
        
        Args:
            content: Chunk content
            chunk_metadata: Existing chunk metadata
            original_doc: Original document
            
        Returns:
            Code-specific metadata dictionary
        """
        metadata = {
            "content_analysis": self._analyze_code_content(content),
            "language_context": self._extract_language_context(content, chunk_metadata),
            "code_quality": self._assess_code_quality(content, chunk_metadata),
            "educational_value": self._assess_educational_value(content, chunk_metadata),
            "reusability_score": self._calculate_reusability_score(content, chunk_metadata),
            "chunking_strategy": "code_modular"
        }
        
        # Add element-specific context
        element_type = chunk_metadata.get('element_type', 'unknown')
        if element_type != 'unknown':
            metadata["element_context"] = self._extract_element_context(content, element_type)
        
        return metadata
    
    def _analyze_code_content(self, content: str) -> Dict[str, Any]:
        """Analyze the code content characteristics.
        
        Args:
            content: Code content
            
        Returns:
            Content analysis metrics
        """
        lines = content.split('\n')
        non_empty_lines = [line for line in lines if line.strip()]
        comment_lines = [line for line in lines if line.strip().startswith(('#', '//', '/*', '--'))]
        
        return {
            "total_lines": len(lines),
            "code_lines": len(non_empty_lines) - len(comment_lines),
            "comment_lines": len(comment_lines),
            "blank_lines": len(lines) - len(non_empty_lines),
            "comment_ratio": len(comment_lines) / len(non_empty_lines) if non_empty_lines else 0,
            "avg_line_length": sum(len(line) for line in lines) / len(lines) if lines else 0,
            "max_line_length": max(len(line) for line in lines) if lines else 0,
            "indentation_consistency": self._check_indentation_consistency(lines),
            "has_documentation": '"""' in content or "'''" in content or '/*' in content
        }
    
    def _extract_language_context(self, content: str, chunk_metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Extract programming language context.
        
        Args:
            content: Code content
            chunk_metadata: Chunk metadata
            
        Returns:
            Language context information
        """
        language = chunk_metadata.get('language', 'unknown')
        
        context = {
            "language": language,
            "paradigm": self._identify_programming_paradigm(content, language),
            "framework_indicators": self._identify_frameworks(content, language),
            "version_indicators": self._identify_language_version(content, language),
            "style_conventions": self._analyze_style_conventions(content, language)
        }
        
        return context
    
    def _assess_code_quality(self, content: str, chunk_metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Assess code quality indicators.
        
        Args:
            content: Code content
            chunk_metadata: Chunk metadata
            
        Returns:
            Code quality assessment
        """
        # Get complexity from metadata if available
        complexity = chunk_metadata.get('complexity', 0)
        
        quality_score = 100  # Start with perfect score
        
        # Deduct points for various quality issues
        if complexity > 10:
            quality_score -= 20
        elif complexity > 5:
            quality_score -= 10
        
        # Check for long lines
        lines = content.split('\n')
        long_lines = [line for line in lines if len(line) > 120]
        if len(long_lines) > len(lines) * 0.3:
            quality_score -= 15
        
        # Check for documentation
        has_docs = '"""' in content or "'''" in content
        if not has_docs and len(content) > 500:
            quality_score -= 10
        
        # Check for meaningful naming
        if self._has_meaningful_names(content):
            quality_score += 5
        else:
            quality_score -= 10
        
        return {
            "quality_score": max(0, quality_score),
            "complexity_level": "low" if complexity < 3 else "medium" if complexity < 8 else "high",
            "readability_indicators": {
                "has_documentation": has_docs,
                "reasonable_line_length": len(long_lines) / len(lines) < 0.1 if lines else True,
                "meaningful_names": self._has_meaningful_names(content)
            }
        }
    
    def _assess_educational_value(self, content: str, chunk_metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Assess educational value of the code chunk.
        
        Args:
            content: Code content
            chunk_metadata: Chunk metadata
            
        Returns:
            Educational value assessment
        """
        educational_indicators = []
        
        # Check for common educational patterns
        if 'example' in content.lower() or 'demo' in content.lower():
            educational_indicators.append("example_code")
        
        if '"""' in content or "'''" in content:
            educational_indicators.append("well_documented")
        
        if 'TODO' in content or 'FIXME' in content:
            educational_indicators.append("learning_opportunity")
        
        # Check complexity level for learning
        complexity = chunk_metadata.get('complexity', 0)
        if 2 <= complexity <= 6:
            educational_indicators.append("good_complexity_for_learning")
        
        # Check for design patterns
        element_type = chunk_metadata.get('element_type', 'unknown')
        if element_type in ['class', 'interface']:
            educational_indicators.append("object_oriented_concepts")
        
        return {
            "educational_indicators": educational_indicators,
            "learning_level": self._determine_learning_level(content, chunk_metadata),
            "concepts_demonstrated": self._identify_programming_concepts(content)
        }
    
    def _calculate_reusability_score(self, content: str, chunk_metadata: Dict[str, Any]) -> int:
        """Calculate reusability score for the code chunk.
        
        Args:
            content: Code content
            chunk_metadata: Chunk metadata
            
        Returns:
            Reusability score (0-100)
        """
        score = 50  # Base score
        
        # Higher score for certain element types
        element_type = chunk_metadata.get('element_type', 'unknown')
        if element_type in ['function', 'class', 'interface']:
            score += 20
        elif element_type == 'method':
            score += 10
        
        # Higher score for documented code
        if '"""' in content or "'''" in content:
            score += 15
        
        # Higher score for parameterized code
        if 'def ' in content and '(' in content:
            param_count = content.count(',') + 1 if '(' in content else 0
            if param_count > 0:
                score += min(15, param_count * 3)
        
        # Lower score for hardcoded values
        if any(pattern in content for pattern in ['localhost', '127.0.0.1', 'C:\\', '/tmp/']):
            score -= 10
        
        # Lower score for very specific implementations
        if any(keyword in content.lower() for keyword in ['specific', 'hardcode', 'hack', 'temporary']):
            score -= 15
        
        return max(0, min(100, score))
    
    def _generate_chunk_title(self, original_doc: Document, chunk_metadata: Dict[str, Any], 
                            chunk_index: int) -> str:
        """Generate a descriptive title for the code chunk.
        
        Args:
            original_doc: Original document
            chunk_metadata: Chunk metadata
            chunk_index: Chunk index
            
        Returns:
            Generated chunk title
        """
        base_title = original_doc.title
        
        # Try to use element name if available
        element_name = chunk_metadata.get('element_name')
        element_type = chunk_metadata.get('element_type', 'code')
        language = chunk_metadata.get('language', 'unknown')
        
        if element_name and element_name != 'unknown':
            if element_type in ['function', 'method']:
                return f"{base_title} - {element_type.title()}: {element_name}()"
            elif element_type == 'class':
                return f"{base_title} - Class: {element_name}"
            else:
                return f"{base_title} - {element_type.title()}: {element_name}"
        
        # Fallback to generic naming
        if language != 'unknown':
            return f"{base_title} - {language.title()} Code Chunk {chunk_index + 1}"
        else:
            return f"{base_title} - Code Chunk {chunk_index + 1}"
    
    def _is_minified_code(self, content: str) -> bool:
        """Check if code appears to be minified.
        
        Args:
            content: Code content
            
        Returns:
            True if code appears minified
        """
        lines = content.split('\n')
        if not lines:
            return False
        
        # Check for very long lines (typical of minified code)
        avg_line_length = sum(len(line) for line in lines) / len(lines)
        max_line_length = max(len(line) for line in lines)
        
        # Check ratio of meaningful characters
        meaningful_chars = sum(1 for char in content if char.isalnum() or char in '_$')
        total_chars = len(content)
        meaningful_ratio = meaningful_chars / total_chars if total_chars > 0 else 0
        
        return (
            avg_line_length > 200 or
            max_line_length > 1000 or
            meaningful_ratio < self.skip_conditions["minified_code_threshold"]
        )
    
    def _is_generated_code(self, content: str) -> bool:
        """Check if code appears to be auto-generated.
        
        Args:
            content: Code content
            
        Returns:
            True if code appears auto-generated
        """
        content_lower = content.lower()
        return any(pattern in content_lower for pattern in self.skip_conditions["generated_code_patterns"])
    
    def _is_mostly_comments(self, content: str) -> bool:
        """Check if content is mostly comments.
        
        Args:
            content: Code content
            
        Returns:
            True if content is mostly comments
        """
        lines = content.split('\n')
        comment_lines = sum(1 for line in lines if line.strip().startswith(('#', '//', '/*', '--')))
        non_empty_lines = sum(1 for line in lines if line.strip())
        
        return comment_lines / non_empty_lines > 0.8 if non_empty_lines > 0 else False
    
    def _check_indentation_consistency(self, lines: list) -> bool:
        """Check if indentation is consistent.
        
        Args:
            lines: List of code lines
            
        Returns:
            True if indentation is consistent
        """
        indentations = []
        for line in lines:
            if line.strip():  # Only check non-empty lines
                leading_spaces = len(line) - len(line.lstrip())
                if leading_spaces > 0:
                    indentations.append(leading_spaces)
        
        if not indentations:
            return True
        
        # Check if indentations follow a pattern (multiples of 2, 4, or 8)
        for base in [2, 4, 8]:
            if all(indent % base == 0 for indent in indentations):
                return True
        
        return False
    
    def _identify_programming_paradigm(self, content: str, language: str) -> str:
        """Identify the programming paradigm used.
        
        Args:
            content: Code content
            language: Programming language
            
        Returns:
            Identified paradigm
        """
        paradigms = []
        
        if 'class ' in content:
            paradigms.append("object_oriented")
        if any(keyword in content for keyword in ['def ', 'function ', 'func ']):
            paradigms.append("procedural")
        if any(keyword in content for keyword in ['lambda', 'map(', 'filter(', 'reduce(']):
            paradigms.append("functional")
        if 'async' in content or 'await' in content:
            paradigms.append("asynchronous")
        
        return paradigms[0] if paradigms else "unknown"
    
    def _identify_frameworks(self, content: str, language: str) -> list:
        """Identify frameworks used in the code.
        
        Args:
            content: Code content
            language: Programming language
            
        Returns:
            List of identified frameworks
        """
        frameworks = []
        content_lower = content.lower()
        
        # Python frameworks
        if language == "python":
            framework_indicators = {
                "django": ["django", "models.model", "request.get"],
                "flask": ["flask", "app.route", "@app."],
                "fastapi": ["fastapi", "pydantic", "async def"],
                "pandas": ["pandas", "dataframe", "pd."],
                "numpy": ["numpy", "np.", "array"],
                "tensorflow": ["tensorflow", "tf.", "keras"],
                "pytorch": ["torch", "pytorch", "tensor"]
            }
        elif language in ["javascript", "typescript"]:
            framework_indicators = {
                "react": ["react", "usestate", "component"],
                "vue": ["vue", "v-if", "v-for"],
                "angular": ["angular", "@component", "ngfor"],
                "express": ["express", "app.get", "middleware"],
                "jquery": ["jquery", "$", ".click"]
            }
        else:
            framework_indicators = {}
        
        for framework, indicators in framework_indicators.items():
            if any(indicator in content_lower for indicator in indicators):
                frameworks.append(framework)
        
        return frameworks
    
    def _identify_language_version(self, content: str, language: str) -> str:
        """Identify language version indicators.
        
        Args:
            content: Code content
            language: Programming language
            
        Returns:
            Version indicators
        """
        if language == "python":
            if ':=' in content:
                return "3.8+"
            elif 'f"' in content or "f'" in content:
                return "3.6+"
            elif 'async def' in content:
                return "3.5+"
            elif 'yield from' in content:
                return "3.3+"
        elif language == "javascript":
            if '=>' in content:
                return "ES6+"
            elif 'const ' in content or 'let ' in content:
                return "ES6+"
        
        return "unknown"
    
    def _analyze_style_conventions(self, content: str, language: str) -> Dict[str, Any]:
        """Analyze coding style conventions.
        
        Args:
            content: Code content
            language: Programming language
            
        Returns:
            Style analysis
        """
        conventions = {}
        
        if language == "python":
            # Check naming conventions
            conventions["snake_case_functions"] = bool(re.search(r'def [a-z_]+\(', content))
            conventions["pascal_case_classes"] = bool(re.search(r'class [A-Z][a-zA-Z]*', content))
            
        elif language in ["javascript", "typescript"]:
            # Check naming conventions
            conventions["camel_case_functions"] = bool(re.search(r'function [a-z][a-zA-Z]*\(', content))
            conventions["pascal_case_classes"] = bool(re.search(r'class [A-Z][a-zA-Z]*', content))
        
        return conventions
    
    def _has_meaningful_names(self, content: str) -> bool:
        """Check if the code uses meaningful variable/function names.
        
        Args:
            content: Code content
            
        Returns:
            True if names appear meaningful
        """
        # Extract identifiers
        import re
        identifiers = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', content)
        
        # Filter out keywords and single character names
        meaningful_names = [
            name for name in identifiers 
            if len(name) > 2 and name not in ['def', 'class', 'for', 'if', 'else', 'try', 'except']
        ]
        
        # Check for non-descriptive patterns
        non_descriptive = [name for name in meaningful_names if re.match(r'^[a-z]{1,2}\d*$', name)]
        
        if not meaningful_names:
            return True  # No names to judge
        
        return len(non_descriptive) / len(meaningful_names) < 0.3
    
    def _determine_learning_level(self, content: str, chunk_metadata: Dict[str, Any]) -> str:
        """Determine the learning level of the code.
        
        Args:
            content: Code content
            chunk_metadata: Chunk metadata
            
        Returns:
            Learning level (beginner, intermediate, advanced)
        """
        complexity = chunk_metadata.get('complexity', 0)
        element_type = chunk_metadata.get('element_type', 'unknown')
        
        # Advanced indicators
        advanced_patterns = ['metaclass', 'decorator', 'generator', 'async', 'threading', 'multiprocessing']
        if any(pattern in content.lower() for pattern in advanced_patterns):
            return "advanced"
        
        # Intermediate indicators
        if complexity > 5 or element_type in ['class', 'interface']:
            return "intermediate"
        
        # Simple function or straightforward code
        if complexity <= 3 and len(content.split('\n')) < 20:
            return "beginner"
        
        return "intermediate"
    
    def _identify_programming_concepts(self, content: str) -> list:
        """Identify programming concepts demonstrated in the code.
        
        Args:
            content: Code content
            
        Returns:
            List of programming concepts
        """
        concepts = []
        content_lower = content.lower()
        
        # Basic concepts
        if 'if ' in content_lower:
            concepts.append("conditionals")
        if 'for ' in content_lower or 'while ' in content_lower:
            concepts.append("loops")
        if 'def ' in content_lower or 'function ' in content_lower:
            concepts.append("functions")
        if 'class ' in content_lower:
            concepts.append("classes")
        
        # Advanced concepts
        if 'try:' in content_lower or 'except:' in content_lower:
            concepts.append("exception_handling")
        if 'async' in content_lower:
            concepts.append("asynchronous_programming")
        if 'yield' in content_lower:
            concepts.append("generators")
        if '@' in content:
            concepts.append("decorators")
        if 'lambda' in content_lower:
            concepts.append("lambda_functions")
        
        return concepts
    
    def _extract_element_context(self, content: str, element_type: str) -> Dict[str, Any]:
        """Extract context specific to the code element type.
        
        Args:
            content: Code content
            element_type: Type of code element
            
        Returns:
            Element-specific context
        """
        context = {"element_type": element_type}
        
        if element_type in ['function', 'method']:
            context.update({
                "parameter_count": content.count(',') + 1 if '(' in content else 0,
                "has_return_statement": 'return ' in content,
                "has_docstring": '"""' in content or "'''" in content,
                "is_recursive": content.count(self._extract_function_name(content)) > 1
            })
        elif element_type == 'class':
            context.update({
                "method_count": content.count('def '),
                "has_constructor": '__init__' in content or 'constructor' in content,
                "has_inheritance": 'extends' in content or '(' in content.split('class')[1].split(':')[0],
                "has_docstring": '"""' in content or "'''" in content
            })
        
        return context
    
    def _extract_function_name(self, content: str) -> str:
        """Extract function name from content.
        
        Args:
            content: Code content
            
        Returns:
            Function name or empty string
        """
        import re
        match = re.search(r'def\s+([a-zA-Z_][a-zA-Z0-9_]*)', content)
        return match.group(1) if match else "" 