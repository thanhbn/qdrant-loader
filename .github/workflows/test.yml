name: Test and Coverage

on:
  push:
    branches: [ main, develop, feature/*, bugfix/*, release/*, fix/* ]
  pull_request:
    branches: [ main, develop, feature/*, bugfix/*, release/*, fix/* ]

permissions:
  contents: read
  actions: read

concurrency:
  group: "test-${{ github.ref }}"
  cancel-in-progress: true

jobs:
  test-core:
    name: Test Core Package
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Restore cached virtual environment
        uses: actions/cache/restore@v4
        id: cache-venv-core
        with:
          path: .venv
          key: ${{ runner.os }}-venv-core-${{ hashFiles('packages/qdrant-loader-core/pyproject.toml', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-venv-core-

      - name: Create venv if not cached
        if: steps.cache-venv-core.outputs.cache-hit != 'true'
        run: python -m venv .venv

      - name: Install dependencies
        run: |
          source .venv/bin/activate
          python -m pip install --upgrade pip
          # Install core with extras used in tests
          pip install -e packages/qdrant-loader-core[openai,ollama]
          # Install repo dev deps for pytest, coverage, etc.
          pip install -e .[dev]

      - name: Save virtual environment cache
        uses: actions/cache/save@v4
        if: steps.cache-venv-core.outputs.cache-hit != 'true'
        with:
          path: .venv
          key: ${{ runner.os }}-venv-core-${{ hashFiles('packages/qdrant-loader-core/pyproject.toml', 'pyproject.toml') }}

      - name: Activate venv for subsequent steps
        run: echo "${{ github.workspace }}/.venv/bin" >> $GITHUB_PATH

      - name: Run core tests and generate coverage reports
        run: |
          cd packages/qdrant-loader-core
          python -m pytest tests/ --cov=src --cov-report=xml:../../coverage-core.xml --cov-report=html:../../htmlcov-core -v

      - name: Upload core coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-core-${{ github.run_id }}
          path: |
            htmlcov-core
            coverage-core.xml
          retention-days: 30
  test-loader:
    name: Test QDrant Loader
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install system dependencies
        run: |
          # Install ffmpeg for full MarkItDown audio processing capabilities
          # This ensures comprehensive file conversion testing including audio files
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Restore cached virtual environment
        uses: actions/cache/restore@v4
        id: cache-venv-loader
        with:
          path: .venv
          key: ${{ runner.os }}-venv-loader-${{ hashFiles('packages/qdrant-loader-core/pyproject.toml', 'packages/qdrant-loader/pyproject.toml', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-venv-loader-

      - name: Create venv if not cached
        if: steps.cache-venv-loader.outputs.cache-hit != 'true'
        run: python -m venv .venv

      - name: Install dependencies
        run: |
          source .venv/bin/activate
          python -m pip install --upgrade pip
          # Install monorepo packages locally in dependency order to avoid PyPI resolution
          pip install -e packages/qdrant-loader-core[openai]
          pip install -e .[dev]
          pip install -e packages/qdrant-loader

      - name: Save virtual environment cache
        uses: actions/cache/save@v4
        if: steps.cache-venv-loader.outputs.cache-hit != 'true'
        with:
          path: .venv
          key: ${{ runner.os }}-venv-loader-${{ hashFiles('packages/qdrant-loader-core/pyproject.toml', 'packages/qdrant-loader/pyproject.toml', 'pyproject.toml') }}

      - name: Activate venv for subsequent steps
        run: echo "${{ github.workspace }}/.venv/bin" >> $GITHUB_PATH

      - name: Create .env.test file for loader
        run: |
          cd packages/qdrant-loader
          cp tests/.env.test.template tests/.env.test
          
          # Check if required secrets are set
          if [ -z "${{ secrets.QDRANT_URL }}" ]; then
            echo "Error: QDRANT_URL secret is not set"
            exit 1
          fi
          if [ -z "${{ secrets.QDRANT_API_KEY }}" ]; then
            echo "Error: QDRANT_API_KEY secret is not set"
            exit 1
          fi
          if [ -z "${{ secrets.QDRANT_COLLECTION_NAME }}" ]; then
            echo "Error: QDRANT_COLLECTION_NAME secret is not set"
            exit 1
          fi
          if [ -z "${{ secrets.OPENAI_API_KEY }}" ]; then
            echo "Error: OPENAI_API_KEY secret is not set"
            exit 1
          fi
          
          # Replace environment variables with proper escaping
          sed -i "s|QDRANT_URL=.*|QDRANT_URL=${{ secrets.QDRANT_URL }}|g" tests/.env.test
          sed -i "s|QDRANT_API_KEY=.*|QDRANT_API_KEY=${{ secrets.QDRANT_API_KEY }}|g" tests/.env.test
          sed -i "s|QDRANT_COLLECTION_NAME=.*|QDRANT_COLLECTION_NAME=${{ secrets.QDRANT_COLLECTION_NAME }}|g" tests/.env.test
          sed -i "s|OPENAI_API_KEY=.*|OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}|g" tests/.env.test
          sed -i "s|STATE_DB_PATH=.*|STATE_DB_PATH=:memory:|g" tests/.env.test
          
          # Optional secrets - only replace if they exist
          if [ -n "${{ secrets.REPO_TOKEN }}" ]; then
            sed -i "s|REPO_TOKEN=.*|REPO_TOKEN=${{ secrets.REPO_TOKEN }}|g" tests/.env.test
          fi
          if [ -n "${{ secrets.REPO_URL }}" ]; then
            sed -i "s|REPO_URL=.*|REPO_URL=${{ secrets.REPO_URL }}|g" tests/.env.test
          fi
          if [ -n "${{ secrets.CONFLUENCE_TOKEN }}" ]; then
            sed -i "s|CONFLUENCE_TOKEN=.*|CONFLUENCE_TOKEN=${{ secrets.CONFLUENCE_TOKEN }}|g" tests/.env.test
          fi
          if [ -n "${{ secrets.CONFLUENCE_EMAIL }}" ]; then
            sed -i "s|CONFLUENCE_EMAIL=.*|CONFLUENCE_EMAIL=${{ secrets.CONFLUENCE_EMAIL }}|g" tests/.env.test
          fi
          if [ -n "${{ secrets.CONFLUENCE_URL }}" ]; then
            sed -i "s|CONFLUENCE_URL=.*|CONFLUENCE_URL=${{ secrets.CONFLUENCE_URL }}|g" tests/.env.test
          fi
          if [ -n "${{ secrets.CONFLUENCE_SPACE_KEY }}" ]; then
            sed -i "s|CONFLUENCE_SPACE_KEY=.*|CONFLUENCE_SPACE_KEY=${{ secrets.CONFLUENCE_SPACE_KEY }}|g" tests/.env.test
          fi
          if [ -n "${{ secrets.JIRA_TOKEN }}" ]; then
            sed -i "s|JIRA_TOKEN=.*|JIRA_TOKEN=${{ secrets.JIRA_TOKEN }}|g" tests/.env.test
          fi
          if [ -n "${{ secrets.JIRA_EMAIL }}" ]; then
            sed -i "s|JIRA_EMAIL=.*|JIRA_EMAIL=${{ secrets.JIRA_EMAIL }}|g" tests/.env.test
          fi
          if [ -n "${{ secrets.JIRA_URL }}" ]; then
            sed -i "s|JIRA_URL=.*|JIRA_URL=${{ secrets.JIRA_URL }}|g" tests/.env.test
          fi
          if [ -n "${{ secrets.JIRA_PROJECT_KEY }}" ]; then
            sed -i "s|JIRA_PROJECT_KEY=.*|JIRA_PROJECT_KEY=${{ secrets.JIRA_PROJECT_KEY }}|g" tests/.env.test
          fi
          
          echo "Created .env.test file successfully"
          echo "Contents (with secrets masked):"
          sed 's/=.*/=***/' tests/.env.test

      - name: Create config.test.yaml file for loader
        run: |
          cd packages/qdrant-loader
          cp tests/config.test.template.yaml tests/config.test.yaml
          
          # Replace environment variables in YAML config
          sed -i "s|\${QDRANT_URL}|${{ secrets.QDRANT_URL }}|g" tests/config.test.yaml
          sed -i "s|\${QDRANT_API_KEY}|${{ secrets.QDRANT_API_KEY }}|g" tests/config.test.yaml
          sed -i "s|\${QDRANT_COLLECTION_NAME}|${{ secrets.QDRANT_COLLECTION_NAME }}|g" tests/config.test.yaml
          
          # Optional environment variables - only replace if they exist
          if [ -n "${{ secrets.REPO_TOKEN }}" ]; then
            sed -i "s|\${REPO_TOKEN}|${{ secrets.REPO_TOKEN }}|g" tests/config.test.yaml
          fi
          if [ -n "${{ secrets.REPO_URL }}" ]; then
            sed -i "s|\${REPO_URL}|${{ secrets.REPO_URL }}|g" tests/config.test.yaml
          fi
          if [ -n "${{ secrets.CONFLUENCE_TOKEN }}" ]; then
            sed -i "s|\${CONFLUENCE_TOKEN}|${{ secrets.CONFLUENCE_TOKEN }}|g" tests/config.test.yaml
          fi
          if [ -n "${{ secrets.CONFLUENCE_EMAIL }}" ]; then
            sed -i "s|\${CONFLUENCE_EMAIL}|${{ secrets.CONFLUENCE_EMAIL }}|g" tests/config.test.yaml
          fi
          if [ -n "${{ secrets.CONFLUENCE_URL }}" ]; then
            sed -i "s|\${CONFLUENCE_URL}|${{ secrets.CONFLUENCE_URL }}|g" tests/config.test.yaml
          fi
          if [ -n "${{ secrets.CONFLUENCE_SPACE_KEY }}" ]; then
            sed -i "s|\${CONFLUENCE_SPACE_KEY}|${{ secrets.CONFLUENCE_SPACE_KEY }}|g" tests/config.test.yaml
          fi
          if [ -n "${{ secrets.JIRA_TOKEN }}" ]; then
            sed -i "s|\${JIRA_TOKEN}|${{ secrets.JIRA_TOKEN }}|g" tests/config.test.yaml
          fi
          if [ -n "${{ secrets.JIRA_EMAIL }}" ]; then
            sed -i "s|\${JIRA_EMAIL}|${{ secrets.JIRA_EMAIL }}|g" tests/config.test.yaml
          fi
          if [ -n "${{ secrets.JIRA_URL }}" ]; then
            sed -i "s|\${JIRA_URL}|${{ secrets.JIRA_URL }}|g" tests/config.test.yaml
          fi
          if [ -n "${{ secrets.JIRA_PROJECT_KEY }}" ]; then
            sed -i "s|\${JIRA_PROJECT_KEY}|${{ secrets.JIRA_PROJECT_KEY }}|g" tests/config.test.yaml
          fi
          
          echo "Created config.test.yaml file successfully"
          echo "YAML config structure:"
          head -20 tests/config.test.yaml

      - name: Run loader tests and generate coverage reports
        run: |
          cd packages/qdrant-loader
          python -m pytest tests/ --cov=src --cov-report=xml:../../coverage-loader.xml --cov-report=html:../../htmlcov-loader -v

      - name: Upload loader coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-loader-${{ github.run_id }}
          path: |
            htmlcov-loader
            coverage-loader.xml
          retention-days: 30

  test-mcp-server:
    name: Test MCP Server
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Restore cached virtual environment
        uses: actions/cache/restore@v4
        id: cache-venv-mcp
        with:
          path: .venv
          key: ${{ runner.os }}-venv-mcp-${{ hashFiles('packages/qdrant-loader-core/pyproject.toml', 'packages/qdrant-loader/pyproject.toml', 'packages/qdrant-loader-mcp-server/pyproject.toml', 'pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-venv-mcp-

      - name: Create venv if not cached
        if: steps.cache-venv-mcp.outputs.cache-hit != 'true'
        run: python -m venv .venv

      - name: Install dependencies
        run: |
          source .venv/bin/activate
          python -m pip install --upgrade pip
          # Install monorepo packages locally in dependency order to avoid PyPI resolution
          pip install -e packages/qdrant-loader-core
          pip install -e .[dev]
          pip install -e packages/qdrant-loader
          pip install -e packages/qdrant-loader-mcp-server

      - name: Save virtual environment cache
        uses: actions/cache/save@v4
        if: steps.cache-venv-mcp.outputs.cache-hit != 'true'
        with:
          path: .venv
          key: ${{ runner.os }}-venv-mcp-${{ hashFiles('packages/qdrant-loader-core/pyproject.toml', 'packages/qdrant-loader/pyproject.toml', 'packages/qdrant-loader-mcp-server/pyproject.toml', 'pyproject.toml') }}

      - name: Activate venv for subsequent steps
        run: echo "${{ github.workspace }}/.venv/bin" >> $GITHUB_PATH

      - name: Create .env.test file for MCP server
        run: |
          cd packages/qdrant-loader-mcp-server
          cp tests/.env.test.template tests/.env.test
          
          # Check if required secrets are set
          if [ -z "${{ secrets.QDRANT_URL }}" ]; then
            echo "Error: QDRANT_URL secret is not set"
            exit 1
          fi
          if [ -z "${{ secrets.QDRANT_API_KEY }}" ]; then
            echo "Error: QDRANT_API_KEY secret is not set"
            exit 1
          fi
          if [ -z "${{ secrets.QDRANT_COLLECTION_NAME }}" ]; then
            echo "Error: QDRANT_COLLECTION_NAME secret is not set"
            exit 1
          fi
          if [ -z "${{ secrets.OPENAI_API_KEY }}" ]; then
            echo "Error: OPENAI_API_KEY secret is not set"
            exit 1
          fi
          
          # Replace environment variables with secrets for integration tests
          sed -i "s|QDRANT_URL=.*|QDRANT_URL=${{ secrets.QDRANT_URL }}|g" tests/.env.test
          sed -i "s|QDRANT_API_KEY=.*|QDRANT_API_KEY=${{ secrets.QDRANT_API_KEY }}|g" tests/.env.test
          sed -i "s|QDRANT_COLLECTION_NAME=.*|QDRANT_COLLECTION_NAME=${{ secrets.QDRANT_COLLECTION_NAME }}|g" tests/.env.test
          sed -i "s|OPENAI_API_KEY=.*|OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}|g" tests/.env.test
          
          echo "Created .env.test file for MCP server successfully"
          echo "Contents (with secrets masked):"
          sed 's/=.*/=***/' tests/.env.test

      - name: Run MCP server tests (fast parallel scan)
        id: fast-test
        run: |
          cd packages/qdrant-loader-mcp-server
          # Step 1: Fast parallel run to find failures quickly
          python -m pytest tests/ -n auto -qq --cov=src --cov-report=xml:../../coverage-mcp.xml --cov-report=html:../../htmlcov-mcp || echo "TESTS_FAILED=true" >> $GITHUB_ENV

      - name: Re-run failed tests with verbose output
        if: env.TESTS_FAILED == 'true'
        run: |
          cd packages/qdrant-loader-mcp-server
          # Step 2: Re-run only failed tests with verbose output for debugging
          echo "=== Re-running failed tests with verbose output ==="
          python -m pytest tests/ -v --lf --tb=long
          # Exit with failure after showing verbose output
          exit 1

      - name: Upload MCP server coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-mcp-${{ github.run_id }}
          path: |
            htmlcov-mcp
            coverage-mcp.xml
          retention-days: 30

  test-website:
    name: Test Website Build System
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install system dependencies for website testing
        run: |
          # Install system dependencies that might be needed for favicon generation
          sudo apt-get update
          sudo apt-get install -y libcairo2-dev libgirepository1.0-dev

      - name: Restore cached virtual environment
        uses: actions/cache/restore@v4
        id: cache-venv-website
        with:
          path: .venv
          key: ${{ runner.os }}-venv-website-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-venv-website-

      - name: Create venv if not cached
        if: steps.cache-venv-website.outputs.cache-hit != 'true'
        run: python -m venv .venv

      - name: Install website test dependencies
        run: |
          source .venv/bin/activate
          python -m pip install --upgrade pip
          # Install dev dependencies from root pyproject.toml which includes requests, responses, and other test dependencies
          pip install -e .[dev]
          # Install optional docs dependencies for comprehensive testing
          pip install -e .[docs] || echo "Optional docs dependencies not available"

      - name: Save virtual environment cache
        uses: actions/cache/save@v4
        if: steps.cache-venv-website.outputs.cache-hit != 'true'
        with:
          path: .venv
          key: ${{ runner.os }}-venv-website-${{ hashFiles('pyproject.toml') }}

      - name: Activate venv for subsequent steps
        run: echo "${{ github.workspace }}/.venv/bin" >> $GITHUB_PATH

      - name: Run website tests with coverage
        run: |
          # Add website directory to Python path and run tests
          export PYTHONPATH="${PYTHONPATH}:$(pwd)/website"
          python -m pytest tests/ --cov=website --cov-report=xml:coverage-website.xml --cov-report=html:htmlcov-website --cov-report=term-missing -v

      - name: Upload website test coverage artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-website-${{ github.run_id }}
          path: |
            htmlcov-website
            coverage-website.xml
          retention-days: 30

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-core, test-loader, test-mcp-server, test-website]
    if: always()
    steps:
      - name: Check test results
        run: |
          echo "=== Test Results Summary ==="
          echo "Core Package Tests: ${{ needs.test-core.result }}"
          echo "QDrant Loader Tests: ${{ needs.test-loader.result }}"
          echo "MCP Server Tests: ${{ needs.test-mcp-server.result }}"
          echo "Website Build Tests: ${{ needs.test-website.result }}"
          
          if [ "${{ needs.test-core.result }}" != "success" ] || [ "${{ needs.test-loader.result }}" != "success" ] || [ "${{ needs.test-mcp-server.result }}" != "success" ] || [ "${{ needs.test-website.result }}" != "success" ]; then
            echo "âŒ Some tests failed"
            exit 1
          else
            echo "âœ… All tests passed"
          fi

      - name: Create test status artifact
        run: |
          mkdir -p test-results
          echo "{\n            \"core_status\": \"${{ needs.test-core.result }}\",\n            \"loader_status\": \"${{ needs.test-loader.result }}\",\n            \"mcp_status\": \"${{ needs.test-mcp-server.result }}\",\n            \"website_status\": \"${{ needs.test-website.result }}\",\n            \"overall_status\": \"${{ (needs.test-core.result == 'success' && needs.test-loader.result == 'success' && needs.test-mcp-server.result == 'success' && needs.test-website.result == 'success') && 'success' || 'failure' }}\",\n            \"run_id\": \"${{ github.run_id }}\",\n            \"commit_sha\": \"${{ github.sha }}\",\n            \"branch\": \"${{ github.ref_name }}\",\n            \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"\n          }" > test-results/status.json
          
          echo "Test run completed at $(date)" > test-results/summary.txt
          echo "Run ID: ${{ github.run_id }}" >> test-results/summary.txt
          echo "Commit: ${{ github.sha }}" >> test-results/summary.txt
          echo "Branch: ${{ github.ref_name }}" >> test-results/summary.txt
          echo "Core Package Tests: ${{ needs.test-core.result }}" >> test-results/summary.txt
          echo "Loader Tests: ${{ needs.test-loader.result }}" >> test-results/summary.txt
          echo "MCP Server Tests: ${{ needs.test-mcp-server.result }}" >> test-results/summary.txt
          echo "Website Tests: ${{ needs.test-website.result }}" >> test-results/summary.txt

      - name: Upload test status artifact
        uses: actions/upload-artifact@v4
        with:
          name: test-status-${{ github.run_id }}
          path: test-results/
          retention-days: 30
